{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00  -2.91390442e-16]\n",
      " [ -6.10320472e-16   1.00000000e+00]\n",
      " [  9.15121544e-17   2.56395025e-16]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "from scipy.spatial.distance import euclidean\n",
    "import pyechonest\n",
    "from pyechonest import song\n",
    "from pyechonest import track\n",
    "from pyechonest import config\n",
    "config.ECHO_NEST_API_KEY=\"DAQJT7WW3IYXQTPOW\"\n",
    "import csv\n",
    "import hdf5_getters\n",
    "import beat_aligned_feats\n",
    "import load_million_song\n",
    "from collections import namedtuple\n",
    "from time import time\n",
    "\n",
    "def get_chord_templates(template_type):\n",
    "    # Create chord templates for major and minor chords\n",
    "    #\n",
    "    # Parameters:\n",
    "    # template_type: string\n",
    "    # --type of template\n",
    "    # --options: 'majmin',\n",
    "    #\n",
    "    # Returns:\n",
    "    # chord_templates: Tx12 np.array\n",
    "    # --first 12 rows are major templates\n",
    "    # --next 12 are minor, last is no chord\n",
    "    \n",
    "    if template_type == 'majmin':\n",
    "        scale_degree_templates = np.zeros([25,3])\n",
    "        chord_templates = np.zeros([25,12])\n",
    "    # major chords\n",
    "    for i in range(12):\n",
    "        scale_degree_templates[i] = np.mod(np.add([0,4,7],i),12)\n",
    "        chord_templates[i][scale_degree_templates[i].astype('int')] = (1./3.)\n",
    "    # minor chords\n",
    "    for i in range(12,24):\n",
    "        scale_degree_templates[i] = np.mod(np.add([0,3,7],i),12)\n",
    "        chord_templates[i][scale_degree_templates[i].astype('int')] = (1./3.)\n",
    "    # no chord\n",
    "    chord_templates[-1,:] = 1./12.\n",
    "\n",
    "    return chord_templates\n",
    "\n",
    "def get_divergence(chroma,chord_templates):\n",
    "    # Compute divergence between chroma and each chord template\n",
    "    #\n",
    "    # Parameters:\n",
    "    # chroma: 1x12 np.array -- pitch class intensity for each pitch\n",
    "    # chord_templates: Tx12 np.array -- templates for each type of chord\n",
    "    #\n",
    "    # Returns:\n",
    "    # divergence: 1xT np.array -- divergence of chroma from each template\n",
    "    \n",
    "    divergence = np.zeros([1,chord_templates.shape[0]])\n",
    "    for i in range(chord_templates.shape[0]):\n",
    "        divergence[0,i] = euclidean(chroma,chord_templates[i])\n",
    "    \n",
    "    return divergence\n",
    "\n",
    "def get_chord_name(index):\n",
    "    # Print name of chord from its index in the template\n",
    "    #\n",
    "    # Parameters:\n",
    "    # index: int -- index of chord from 1 to T\n",
    "    #\n",
    "    # Returns:\n",
    "    # chord_name: string -- name of chord\n",
    "    chords={0:'C',1:'C#',2:'D',3:'D#',4:'E',5:'F',\n",
    "        6:'F#',7:'G',8:'G#',9:'A',10:'A#',11:'B'};\n",
    "    if index < 12:\n",
    "        chord_name = chords[index] + 'M'\n",
    "    elif index < 24:\n",
    "        chord_name = chords[index-12] + 'm'\n",
    "    else:\n",
    "        chord_name = 'no chord'\n",
    "    \n",
    "    return chord_name\n",
    "\n",
    "def get_chord_array(btchromas,template_type):\n",
    "    # Get the chord in each beat of a track\n",
    "    # (beats determined by echonest)\n",
    "    #\n",
    "    # Parameters:\n",
    "    # btchromas: 12 x S np.array -- beat-sync chroma in each segment\n",
    "    #\n",
    "    # Returns:\n",
    "    # chord_array: 1 x S np.array -- chord type in each segment\n",
    "    \n",
    "    chord_templates = get_chord_templates(template_type)\n",
    "    divergence_matrix = np.zeros([chord_templates.shape[0],btchromas.shape[1]])\n",
    "    chord_array = np.zeros(btchromas.shape[1])\n",
    "    # build divergence series\n",
    "    for i in range(btchromas.shape[1]):\n",
    "        divergence_matrix[:,i] = get_divergence(btchromas[:,i],chord_templates)\n",
    "    #div_filt = medfilt(divergence, kernel_size=15)\n",
    "    \n",
    "    div_matrix_filt = medfilt(divergence_matrix,[1,9])\n",
    "    chord_array = np.argmin(div_matrix_filt,axis=0)\n",
    "\n",
    "    return chord_array\n",
    "\n",
    "#def get_tonic_array(track):\n",
    "#    # Get the tonic key in every segment of a track\n",
    "#    #\n",
    "#    # Parameters:\n",
    "#    # track: echonest track object\n",
    "#    #\n",
    "#    # Returns:\n",
    "#    # key_array: 1 x S np.array -- tonic in each segment\n",
    "#\n",
    "#    tonic_pos = 0\n",
    "#    for i in range(0,len(t.sections)):\n",
    "#        section_end = t.sections[i]['start'] + t.sections[i]['duration']\n",
    "#        while(t.beats[tonic_pos]['start'] < section_end and key_pos < len(t.segments)):\n",
    "#            tonic_array[tonic_pos] = t.sections[i]['key']\n",
    "#            tonic_pos += 1\n",
    "#\n",
    "#    return tonic_array\n",
    "\n",
    "def create_feature_vector(btchromas, template_type):\n",
    "    # Create feature vector based on chord content\n",
    "    #\n",
    "    # Parameters:\n",
    "    # h5path: path to h5 file containing track info\n",
    "    #\n",
    "    #\n",
    "    # Returns:\n",
    "    # feature_vector: 1 x S-1 np.array\n",
    "    # -- first value is the percentage of the track that's root major chords,\n",
    "    # -- second value is second degree major chords\n",
    "    # ...\n",
    "    # -- thirteenth value is root minor chords\n",
    "    \n",
    "    #h5 = hdf5_getters.open_h5_file_read(h5path)\n",
    "    #key = hdf5_getters.get_key(h5)\n",
    "    #h5.close()\n",
    "    \n",
    "    chord_array = get_chord_array(btchromas,template_type)\n",
    "    major_chord_array = chord_array[np.nonzero(chord_array < 12)]\n",
    "    minor_chord_array = chord_array[np.nonzero((chord_array > 12) & (chord_array < 24))]\n",
    "    \n",
    "    major_hist = np.histogram(major_chord_array,bins = 12,range = (-0.5,11.5))[0]\n",
    "    minor_hist = np.histogram(minor_chord_array,bins = 12,range = (11.5,23.5))[0]\n",
    "    total_hist = np.concatenate([major_hist,minor_hist])\n",
    "    \n",
    "    key = np.argmax(total_hist)\n",
    "    \n",
    "    #make features relative to tonic\n",
    "    rel_major_hist = np.zeros(12)\n",
    "    rel_minor_hist = np.zeros(12)\n",
    "    for i in range(12):\n",
    "        rel_major_hist[i] = major_hist[np.mod(i+key,12)]\n",
    "        rel_minor_hist[i] = minor_hist[np.mod(i+key,12)]\n",
    "    total_rel_hist = np.concatenate([rel_major_hist,rel_minor_hist])\n",
    "    \n",
    "    feature_vector = total_rel_hist/float(sum(total_rel_hist))\n",
    "    \n",
    "    return feature_vector,key\n",
    "\n",
    "def print_estimated_info(feature_vector,num_top,key):\n",
    "    # Print the estimated key and names of the num_top most frequent chords in a\n",
    "    # feature vector, and their associated topic probabilities\n",
    "    #\n",
    "    # Parameters:\n",
    "    # feature_vector: 1 x S-1 np.array\n",
    "    # -- first value is the percentage of the track that's root major chords,\n",
    "    # -- second value is second degree major chords\n",
    "    # ...\n",
    "    # -- thirteenth value is root minor chords\n",
    "    #\n",
    "    # Returns: none\n",
    "    \n",
    "    print 'key: ' + get_chord_name(key)\n",
    "    top_chords_num = feature_vector.argsort()[-num_top:][::-1]\n",
    "    for i in range(len(top_chords_num)):\n",
    "        if top_chords_num[i] < 12:\n",
    "            abs_chord = np.mod(top_chords_num[i] + key, 12)\n",
    "        else:\n",
    "            abs_chord = np.mod(top_chords_num[i] - 12 + key, 12) + 12\n",
    "        chord_name = get_chord_name(abs_chord)\n",
    "        print chord_name + ' ' + str(feature_vector[top_chords_num[i]])\n",
    "\n",
    "def save_feature_vector(feature_vector,artist,title,id,csvpath):\n",
    "    # Save feature vector to a comma separated values file\n",
    "    #\n",
    "    # Parameters:\n",
    "    # feature_vector: 1 x S-1 np.array -- vector of features\n",
    "    # csvpath: string -- path where CSV file should be saved\n",
    "    #\n",
    "    # Returns: none\n",
    "    \n",
    "    csvrow = str(artist) + ': ' + str(title) + ',' + str(id) + ',' + \\\n",
    "        str(','.join(map(str, feature_vector))) + '\\n'\n",
    "    print csvrow\n",
    "    f = open(csvpath,'a')\n",
    "    f.write(csvrow)\n",
    "    f.close()\n",
    "\n",
    "def save_feature_database(root_path,csvpath):\n",
    "    # Create a database where each song is represented by a line in a CSV file\n",
    "    # as such: artist/title , echonest id , feature_values\n",
    "    #\n",
    "    # Parameters\n",
    "    # root_path: string -- path to MillionSongSubset's data folder\n",
    "    # csvpath: string -- path where the .csv database will be created\n",
    "    #\n",
    "    # Returns: none\n",
    "    \n",
    "    filename_re = \"^[A-Z]{7}[0-9,A-F]{11}\\.h5$\" # Example: TRBIJIA128F425F57D.h5\n",
    "    time_start = time()\n",
    "    for loop_nr, song_rec in enumerate(\n",
    "                                       load_million_song.iterate_folder_songs_extracted(root_path, filename_re)):\n",
    "        \n",
    "        timbre = song_rec.timbre\n",
    "\tsections_start = song_rec.sections_start\n",
    "\tsections_conf = song_rec.sections_conf\n",
    "\tsegments_start = song_rec.segments_start\n",
    "        poly_feature = get_feature_vector(timbre,sections_start,sections_conf,segments_start)\n",
    "        artist = song_rec.artist\n",
    "        title = song_rec.title\n",
    "        id = song_rec.id\n",
    "        print id\n",
    "        print artist,':',title\n",
    "        print poly_feature\n",
    "        save_feature_vector(poly_feature,artist,title,id,csvpath)\n",
    "        \n",
    "        if ( (loop_nr + 1) % 1000) == 0:\n",
    "            print \"{0} songs read in {1:.1f} seconds\" \\\n",
    "                .format(loop_nr + 1, time() - time_start)\n",
    "\n",
    "    end_time = time() - time_start\n",
    "    print \"Total: {0} songs read in {1:.1f} seconds\".format(loop_nr + 1, end_time)\n",
    "\n",
    "def get_feature_vector(timbre,sections_start,sections_conf,segments_start):\n",
    "\tbest_section = np.argmax(sections_conf)\n",
    "\tbest_section_start = sections_start[best_section]\n",
    "\tif len(sections_start) > best_section:\n",
    "\t    best_section_end = sections_start[best_section + 1]\n",
    "\telse:\n",
    "\t    best_section_end = float('inf')\n",
    "\tseg_indices = []\n",
    "\tfor i in range(len(segments_start)):\n",
    "\t    if segments_start[i] > best_section_start and segments_start[i] < best_section_end:\n",
    "\t\tseg_indices.append(i)\n",
    "\n",
    "\ttimbre_feature = timbre[seg_indices,:]\n",
    "\ttimestamps = segments_start[seg_indices]\n",
    "\tpoly_feature = get_poly_coefficients(timbre_feature,timestamps,2).reshape(-1)\n",
    "\treturn poly_feature\n",
    "\n",
    "def get_poly_coefficients(timbre_cols, timestamps, order):\n",
    "    assert timbre_cols.shape[0] == timestamps.shape[0]\n",
    "    def fit_series(ser_arr):\n",
    "        return np.polyfit(timestamps, ser_arr, order)\n",
    "    return np.column_stack(tuple(map(fit_series, timbre_cols.transpose())))\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    test = np.array([[0, 0], [1, 1], [4, 2]])\n",
    "    ts = np.array([0, 1, 2])\n",
    "    print get_poly_coefficients(test, ts, 2)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    # Main program\n",
    "    \n",
    "#    root_path = '/Users/victoriadennis/Documents/databases/MillionSongSubset/data'\n",
    "#    csvpath = '/Users/victoriadennis/Documents/databases/MillionSongSubset/features/songs.csv'\n",
    "#    filename_re = 'TRBIJIA128F425F57D.h5'\n",
    "#    save_feature_database(root_path,csvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337.5566"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5 = hdf5_getters.open_h5_file_read('TRBFNEE128F425C676.h5')\n",
    "timbre = hdf5_getters.get_segments_timbre(h5)\n",
    "sections_start = hdf5_getters.get_sections_start(h5)\n",
    "sections_conf = hdf5_getters.get_sections_confidence(h5)\n",
    "segments_start = hdf5_getters.get_segments_start(h5)\n",
    "best_section = 1 + np.argmax(sections_conf[1:])\n",
    "best_section_start = sections_start[best_section]\n",
    "if len(sections_start) > best_section + 1:\n",
    "\t    best_section_end = sections_start[best_section + 1]\n",
    "else:\n",
    "    best_section_end = float('inf')\n",
    "seg_indices = []\n",
    "for i in range(len(segments_start)):\n",
    "    if segments_start[i] > best_section_start and segments_start[i] < best_section_end:\n",
    "        seg_indices.append(i)\n",
    "\n",
    "timbre_feature = timbre[seg_indices,:]\n",
    "timestamps = segments_start[seg_indices]\n",
    "poly_feature = get_poly_coefficients(timbre_feature,timestamps,2).reshape(-1)\n",
    "best_section_start\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing: title,id,-0.383698304166,2.41866699114,-0.316760569695,-0.965648928734,1.75284668351,0.557144502216,1.1883318051,0.0578622568502,-0.806179467107,0.40919350092,0.156841552662,-0.739004032745,7.30829028945,-32.0136948841,1.46450521734,14.0546218777,-24.0024177787,-9.3631781893,-15.7630523711,-0.232020307467,12.8108927538,-6.80237963373,-2.56390949797,9.08515090943,13.3791826255,85.6986196905,82.5006039231,-53.1605127878,-17.8372311865,20.7013893139,1.09934548119,-16.7873899822,-15.6334064075,30.7573556078,11.8269719858,-33.5807045924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_feature_vector(poly_feature,'nothing','title','id','blah.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12.00542,  31.65076,  52.55968,  80.98725])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections_start[[1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
